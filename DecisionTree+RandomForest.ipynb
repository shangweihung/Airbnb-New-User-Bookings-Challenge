{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import make_scorer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Preprocessed features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv('./input/TrainTest_Preprocess.csv')\n",
    "labels = pd.read_csv('./input/label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train+Test - Shape (275547, 18)\n",
      "Label - Shape (213451, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Train+Test - Shape', df_all.shape)\n",
    "print('Label - Shape', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape (213451, 18)\n",
      "X test shape (62096, 18)\n"
     ]
    }
   ],
   "source": [
    "vals = df_all.values\n",
    "Numtrain = len(labels)\n",
    "X_train = vals[:Numtrain]\n",
    "X_test = vals[Numtrain:]\n",
    "print('X train shape',X_train.shape)\n",
    "print('X test shape', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference Kaggle\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def dcg_score(y_true, y_score, k=5):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "\n",
    "    gain = 2 ** y_true - 1\n",
    "\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gain / discounts)\n",
    "\n",
    "\n",
    "def ndcg_score(te_labels, predict, k):\n",
    "    \n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(range(len(predict) + 1))\n",
    "    T = lb.transform(te_labels)\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    # Iterate over each y_true and compute the DCG score\n",
    "    for y_true, y_score in zip(T, predict):\n",
    "        actual = dcg_score(y_true, y_score, k)\n",
    "        best = dcg_score(y_true, y_true, k)\n",
    "        if best == 0:\n",
    "            best = 0.000000001\n",
    "        score = float(actual) / float(best)\n",
    "        scores.append(score)\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "# NDCG Scorer function\n",
    "ndcg_scorer = make_scorer(ndcg_score, needs_proba=True, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def folds_to_split(data,targets,train,test):\n",
    "    data_tr = pd.DataFrame(data).iloc[train]\n",
    "    data_te = pd.DataFrame(data).iloc[test]\n",
    "    labels_tr = pd.DataFrame(targets).iloc[train]\n",
    "    labels_te = pd.DataFrame(targets).iloc[test]\n",
    "    return [data_tr, data_te, labels_tr, labels_te]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -fold\n",
      "0.6203388142234675\n",
      "2 -fold\n",
      "0.6513505338053214\n",
      "3 -fold\n",
      "0.6822330726439281\n",
      "4 -fold\n",
      "0.6859020187168331\n",
      "5 -fold\n",
      "0.6743336612874675\n",
      "5-fold avg nDCG: nDCG_DT    0.662832\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "criterion='entropy'\n",
    "\n",
    "foldnum = 0\n",
    "fold_results = pd.DataFrame()\n",
    "kf = KFold(n_splits=5, random_state=1)\n",
    "\n",
    "for train, test in kf.split(X_train):\n",
    "    [tr_data, te_data, tr_labels, te_labels] = folds_to_split(X_train, labels, train, test)\n",
    "    \n",
    "    \n",
    "    DT =  tree.DecisionTreeClassifier(criterion=criterion)\n",
    "    DT.fit(tr_data, tr_labels.values.ravel())\n",
    "    prob_arr_DT = DT.predict_proba(te_data)\n",
    "    score_DT = ndcg_score(te_labels.as_matrix(), prob_arr_DT, k=5)\n",
    "    \n",
    "    foldnum+=1\n",
    "    print(foldnum, \"-fold\")\n",
    "    fold_results.loc[foldnum, 'nDCG_DT'] = score_DT\n",
    "    print(score_DT)\n",
    "\n",
    "print(\"5-fold avg nDCG:\",fold_results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -fold\n",
      "0.6225225832372667\n",
      "2 -fold\n",
      "0.6562259599869823\n",
      "3 -fold\n",
      "0.6844825593547923\n",
      "4 -fold\n",
      "0.6774899793418753\n",
      "5 -fold\n",
      "0.6782749821657894\n",
      "5-fold avg nDCG: nDCG_DT    0.663799\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "criterion='gini'\n",
    "\n",
    "foldnum = 0\n",
    "fold_results = pd.DataFrame()\n",
    "kf = KFold(n_splits=5, random_state=1)\n",
    "\n",
    "for train, test in kf.split(X_train):\n",
    "    [tr_data, te_data, tr_labels, te_labels] = folds_to_split(X_train, labels, train, test)\n",
    "    \n",
    "    \n",
    "    DT =  tree.DecisionTreeClassifier(criterion=criterion)\n",
    "    DT.fit(tr_data, tr_labels.values.ravel())\n",
    "    prob_arr_DT = DT.predict_proba(te_data)\n",
    "    score_DT = ndcg_score(te_labels.as_matrix(), prob_arr_DT, k=5)\n",
    "    \n",
    "    foldnum+=1\n",
    "    print(foldnum, \"-fold\")\n",
    "    fold_results.loc[foldnum, 'nDCG_DT'] = score_DT\n",
    "    print(score_DT)\n",
    "\n",
    "print(\"5-fold avg nDCG:\",fold_results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different max-path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -fold\n",
      "Max depth 3 ; Score 0.771381\n",
      "Max depth 4 ; Score 0.782531\n",
      "Max depth 5 ; Score 0.782172\n",
      "-------------------------------\n",
      "2 -fold\n",
      "Max depth 3 ; Score 0.810472\n",
      "Max depth 4 ; Score 0.812333\n",
      "Max depth 5 ; Score 0.812603\n",
      "-------------------------------\n",
      "3 -fold\n",
      "Max depth 3 ; Score 0.832128\n",
      "Max depth 4 ; Score 0.833548\n",
      "Max depth 5 ; Score 0.833871\n",
      "-------------------------------\n",
      "4 -fold\n",
      "Max depth 3 ; Score 0.843445\n",
      "Max depth 4 ; Score 0.845496\n",
      "Max depth 5 ; Score 0.845626\n",
      "-------------------------------\n",
      "5 -fold\n",
      "Max depth 3 ; Score 0.832072\n",
      "Max depth 4 ; Score 0.834231\n",
      "Max depth 5 ; Score 0.834570\n",
      "-------------------------------\n",
      "5-fold avg nDCG: nDCG_DT-3    0.817900\n",
      "nDCG_DT-4    0.821628\n",
      "nDCG_DT-5    0.821768\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "criterion='gini'\n",
    "\n",
    "foldnum = 0\n",
    "fold_results = pd.DataFrame()\n",
    "kf = KFold(n_splits=5, random_state=1)\n",
    "\n",
    "for train, test in kf.split(X_train):\n",
    "    [tr_data, te_data, tr_labels, te_labels] = folds_to_split(X_train, labels, train, test)\n",
    "    \n",
    "    foldnum+=1\n",
    "    print(foldnum, \"-fold\")\n",
    "    \n",
    "    for depth in range(3,6):   \n",
    "        DT =  tree.DecisionTreeClassifier(criterion=criterion,max_depth = depth)\n",
    "        DT.fit(tr_data, tr_labels.values.ravel())\n",
    "        prob_arr_DT = DT.predict_proba(te_data)\n",
    "        score_DT = ndcg_score(te_labels.as_matrix(), prob_arr_DT, k=5)\n",
    "\n",
    "        \n",
    "        fold_results.loc[foldnum, 'nDCG_DT-'+str(depth) ] = score_DT\n",
    "        print(\"Max depth %d ; Score %f\" %  (depth, score_DT))\n",
    "        \n",
    "    print(\"-------------------------------\")\n",
    "\n",
    "print(\"5-fold avg nDCG:\",fold_results.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### =>The deeper the max depth, the better the nDCG score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -fold\n",
      "Min samples leaf 5 ; Score 0.782172\n",
      "Min samples leaf 10 ; Score 0.782172\n",
      "Min samples leaf 20 ; Score 0.782172\n",
      "Min samples leaf 40 ; Score 0.782078\n",
      "-------------------------------\n",
      "2 -fold\n",
      "Min samples leaf 5 ; Score 0.812603\n",
      "Min samples leaf 10 ; Score 0.812603\n",
      "Min samples leaf 20 ; Score 0.812603\n",
      "Min samples leaf 40 ; Score 0.812598\n",
      "-------------------------------\n",
      "3 -fold\n",
      "Min samples leaf 5 ; Score 0.833871\n",
      "Min samples leaf 10 ; Score 0.833871\n",
      "Min samples leaf 20 ; Score 0.833871\n",
      "Min samples leaf 40 ; Score 0.833871\n",
      "-------------------------------\n",
      "4 -fold\n",
      "Min samples leaf 5 ; Score 0.845626\n",
      "Min samples leaf 10 ; Score 0.845626\n",
      "Min samples leaf 20 ; Score 0.845626\n",
      "Min samples leaf 40 ; Score 0.845565\n",
      "-------------------------------\n",
      "5 -fold\n",
      "Min samples leaf 5 ; Score 0.834570\n",
      "Min samples leaf 10 ; Score 0.834580\n",
      "Min samples leaf 20 ; Score 0.834580\n",
      "Min samples leaf 40 ; Score 0.834580\n",
      "-------------------------------\n",
      "5-fold avg nDCG:\n",
      " nDCG_DT-5     0.821768\n",
      "nDCG_DT-10    0.821770\n",
      "nDCG_DT-20    0.821770\n",
      "nDCG_DT-40    0.821738\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "criterion='gini'\n",
    "max_depth=5\n",
    "\n",
    "foldnum = 0\n",
    "fold_results = pd.DataFrame()\n",
    "kf = KFold(n_splits=5, random_state=1)\n",
    "\n",
    "for train, test in kf.split(X_train):\n",
    "    [tr_data, te_data, tr_labels, te_labels] = folds_to_split(X_train, labels, train, test)\n",
    "    \n",
    "    foldnum+=1\n",
    "    print(foldnum, \"-fold\")\n",
    "    \n",
    "    for min_leaf in [5,10,20,40]:   \n",
    "        DT =  tree.DecisionTreeClassifier(criterion=criterion,\n",
    "                                          max_depth=max_depth,\n",
    "                                          min_samples_leaf=min_leaf)\n",
    "        \n",
    "        DT.fit(tr_data, tr_labels.values.ravel())\n",
    "        prob_arr_DT = DT.predict_proba(te_data)\n",
    "        score_DT = ndcg_score(te_labels.as_matrix(), prob_arr_DT, k=5)\n",
    "\n",
    "        \n",
    "        fold_results.loc[foldnum, 'nDCG_DT-'+str(min_leaf) ] = score_DT\n",
    "        print(\"Min samples leaf %d ; Score %f\" %  (min_leaf, score_DT))\n",
    "        \n",
    "    print(\"-------------------------------\")\n",
    "\n",
    "print(\"5-fold avg nDCG:\\n\",fold_results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### =>min samples leaf does not matter a lot on score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different max_samples_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -fold\n",
      "Max samples nodes 5 ; Score 0.771725\n",
      "Max samples nodes 10 ; Score 0.771531\n",
      "Max samples nodes 15 ; Score 0.782658\n",
      "-------------------------------\n",
      "2 -fold\n",
      "Max samples nodes 5 ; Score 0.808900\n",
      "Max samples nodes 10 ; Score 0.812545\n",
      "Max samples nodes 15 ; Score 0.812525\n",
      "-------------------------------\n",
      "3 -fold\n",
      "Max samples nodes 5 ; Score 0.832440\n",
      "Max samples nodes 10 ; Score 0.833537\n",
      "Max samples nodes 15 ; Score 0.833547\n",
      "-------------------------------\n",
      "4 -fold\n",
      "Max samples nodes 5 ; Score 0.845168\n",
      "Max samples nodes 10 ; Score 0.845848\n",
      "Max samples nodes 15 ; Score 0.846013\n",
      "-------------------------------\n",
      "5 -fold\n",
      "Max samples nodes 5 ; Score 0.833968\n",
      "Max samples nodes 10 ; Score 0.834345\n",
      "Max samples nodes 15 ; Score 0.834460\n",
      "-------------------------------\n",
      "5-fold avg nDCG:\n",
      " nDCG_DT-5     0.818440\n",
      "nDCG_DT-10    0.819561\n",
      "nDCG_DT-15    0.821841\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "criterion='gini'\n",
    "max_depth=5\n",
    "min_samples_leaf=10\n",
    "\n",
    "foldnum = 0\n",
    "fold_results = pd.DataFrame()\n",
    "kf = KFold(n_splits=5, random_state=1)\n",
    "\n",
    "for train, test in kf.split(X_train):\n",
    "    [tr_data, te_data, tr_labels, te_labels] = folds_to_split(X_train, labels, train, test)\n",
    "    \n",
    "    foldnum+=1\n",
    "    print(foldnum, \"-fold\")\n",
    "    \n",
    "    for max_leaf in [5,10,15]:   \n",
    "        DT =  tree.DecisionTreeClassifier(criterion=criterion,\n",
    "                                          max_depth=max_depth,\n",
    "                                          min_samples_leaf=min_samples_leaf,\n",
    "                                          max_leaf_nodes=max_leaf)\n",
    "        \n",
    "        DT.fit(tr_data, tr_labels.values.ravel())\n",
    "        prob_arr_DT = DT.predict_proba(te_data)\n",
    "        score_DT = ndcg_score(te_labels.as_matrix(), prob_arr_DT, k=5)\n",
    "\n",
    "        \n",
    "        fold_results.loc[foldnum, 'nDCG_DT-'+str(max_leaf) ] = score_DT\n",
    "        print(\"Max samples nodes %d ; Score %f\" %  (max_leaf, score_DT))\n",
    "        \n",
    "    print(\"-------------------------------\")\n",
    "\n",
    "print(\"5-fold avg nDCG:\\n\",fold_results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### =>The more max samples node. the slightly better the score is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameters choosing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -fold\n",
      "Score 0.782658\n",
      "-------------------------------\n",
      "2 -fold\n",
      "Score 0.812525\n",
      "-------------------------------\n",
      "3 -fold\n",
      "Score 0.833547\n",
      "-------------------------------\n",
      "4 -fold\n",
      "Score 0.846013\n",
      "-------------------------------\n",
      "5 -fold\n",
      "Score 0.834460\n",
      "-------------------------------\n",
      "5-fold avg nDCG:\n",
      " nDCG_DT    0.821841\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "foldnum = 0\n",
    "fold_results = pd.DataFrame()\n",
    "kf = KFold(n_splits=5, random_state=1)\n",
    "\n",
    "for train, test in kf.split(X_train):\n",
    "    [tr_data, te_data, tr_labels, te_labels] = folds_to_split(X_train, labels, train, test)\n",
    "    \n",
    "    foldnum+=1\n",
    "    print(foldnum, \"-fold\")\n",
    "    \n",
    "    \n",
    "    DT =  tree.DecisionTreeClassifier(criterion='gini',\n",
    "                                      max_depth=5,\n",
    "                                      min_samples_leaf=10,\n",
    "                                      max_leaf_nodes=15)\n",
    "\n",
    "    DT.fit(tr_data, tr_labels.values.ravel())\n",
    "    prob_arr_DT = DT.predict_proba(te_data)\n",
    "    score_DT = ndcg_score(te_labels.as_matrix(), prob_arr_DT, k=5)\n",
    "\n",
    "\n",
    "    fold_results.loc[foldnum, 'nDCG_DT' ] = score_DT\n",
    "    print(\"Score %f\" %  score_DT)\n",
    "        \n",
    "    print(\"-------------------------------\")\n",
    "\n",
    "print(\"5-fold avg nDCG:\\n\",fold_results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -fold\n",
      "Score 0.782275\n",
      "-------------------------------\n",
      "2 -fold\n",
      "Score 0.811863\n",
      "-------------------------------\n",
      "3 -fold\n",
      "Score 0.833844\n",
      "-------------------------------\n",
      "4 -fold\n",
      "Score 0.845922\n",
      "-------------------------------\n",
      "5 -fold\n",
      "Score 0.834405\n",
      "-------------------------------\n",
      "5-fold avg nDCG:\n",
      " nDCG_DT    0.821662\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "foldnum = 0\n",
    "fold_results = pd.DataFrame()\n",
    "kf = KFold(n_splits=5, random_state=1)\n",
    "\n",
    "for train, test in kf.split(X_train):\n",
    "    [tr_data, te_data, tr_labels, te_labels] = folds_to_split(X_train, labels, train, test)\n",
    "    \n",
    "    foldnum+=1\n",
    "    print(foldnum, \"-fold\")\n",
    "    \n",
    "    \n",
    "    DT =  tree.DecisionTreeClassifier(criterion='gini',\n",
    "                                      max_depth=6,\n",
    "                                      min_samples_leaf=10,\n",
    "                                      max_leaf_nodes=20)\n",
    "\n",
    "    DT.fit(tr_data, tr_labels.values.ravel())\n",
    "    prob_arr_DT = DT.predict_proba(te_data)\n",
    "    score_DT = ndcg_score(te_labels.as_matrix(), prob_arr_DT, k=5)\n",
    "\n",
    "\n",
    "    fold_results.loc[foldnum, 'nDCG_DT' ] = score_DT\n",
    "    print(\"Score %f\" %  score_DT)\n",
    "        \n",
    "    print(\"-------------------------------\")\n",
    "\n",
    "print(\"5-fold avg nDCG:\\n\",fold_results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the best nDCG score can be reached using decision tree: 0.8218"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different max depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -fold\n",
      "Max depth 3 ; Score 0.766815\n",
      "Max depth 4 ; Score 0.768526\n",
      "Max depth 5 ; Score 0.774529\n",
      "Max depth 6 ; Score 0.775507\n",
      "Max depth 7 ; Score 0.775842\n",
      "Max depth 8 ; Score 0.777150\n",
      "-------------------------------\n",
      "2 -fold\n",
      "Max depth 3 ; Score 0.798369\n",
      "Max depth 4 ; Score 0.799777\n",
      "Max depth 5 ; Score 0.806243\n",
      "Max depth 6 ; Score 0.807341\n",
      "Max depth 7 ; Score 0.808139\n",
      "Max depth 8 ; Score 0.809334\n",
      "-------------------------------\n",
      "3 -fold\n",
      "Max depth 3 ; Score 0.818011\n",
      "Max depth 4 ; Score 0.819361\n",
      "Max depth 5 ; Score 0.825170\n",
      "Max depth 6 ; Score 0.828318\n",
      "Max depth 7 ; Score 0.829053\n",
      "Max depth 8 ; Score 0.829696\n",
      "-------------------------------\n",
      "4 -fold\n",
      "Max depth 3 ; Score 0.828725\n",
      "Max depth 4 ; Score 0.829728\n",
      "Max depth 5 ; Score 0.836238\n",
      "Max depth 6 ; Score 0.840118\n",
      "Max depth 7 ; Score 0.841675\n",
      "Max depth 8 ; Score 0.842445\n",
      "-------------------------------\n",
      "5 -fold\n",
      "Max depth 3 ; Score 0.821882\n",
      "Max depth 4 ; Score 0.823740\n",
      "Max depth 5 ; Score 0.828461\n",
      "Max depth 6 ; Score 0.830068\n",
      "Max depth 7 ; Score 0.830690\n",
      "Max depth 8 ; Score 0.831089\n",
      "-------------------------------\n",
      "5-fold avg nDCG:\n",
      " nDCG_RF-3    0.806760\n",
      "nDCG_RF-4    0.808227\n",
      "nDCG_RF-5    0.814128\n",
      "nDCG_RF-6    0.816270\n",
      "nDCG_RF-7    0.817080\n",
      "nDCG_RF-8    0.817943\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "foldnum = 0\n",
    "fold_results = pd.DataFrame()\n",
    "kf = KFold(n_splits=5, random_state=1)\n",
    "\n",
    "for train, test in kf.split(X_train):\n",
    "    [tr_data, te_data, tr_labels, te_labels] = folds_to_split(X_train, labels, train, test)\n",
    "    \n",
    "    foldnum+=1\n",
    "    print(foldnum, \"-fold\")\n",
    "    \n",
    "    for max_depth in range(3, 9):\n",
    "        RF = RandomForestClassifier(n_estimators=600, \n",
    "                                    criterion='gini',\n",
    "                                    max_depth=max_depth)\n",
    "\n",
    "        \n",
    "        RF.fit(tr_data, tr_labels.values.ravel())\n",
    "        prob_arr_RF = RF.predict_proba(te_data)\n",
    "        score_RF = ndcg_score(te_labels.as_matrix(), prob_arr_RF, k=5)\n",
    "\n",
    "        \n",
    "        fold_results.loc[foldnum, 'nDCG_RF-'+str(max_depth) ] = score_RF\n",
    "        print(\"Max depth %d ; Score %f\" %  (max_depth, score_RF))\n",
    "        \n",
    "    print(\"-------------------------------\")\n",
    "\n",
    "print(\"5-fold avg nDCG:\\n\",fold_results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### =>max_depth = 7 or 8 is much better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different min samples leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -fold\n",
      "Min leaf 5 ; Score 0.780115\n",
      "Min leaf 15 ; Score 0.781864\n",
      "Min leaf 30 ; Score 0.781953\n",
      "Min leaf 50 ; Score 0.781664\n",
      "-------------------------------\n",
      "2 -fold\n",
      "Min leaf 5 ; Score 0.811072\n",
      "Min leaf 15 ; Score 0.812471\n",
      "Min leaf 30 ; Score 0.812707\n",
      "Min leaf 50 ; Score 0.813094\n",
      "-------------------------------\n",
      "3 -fold\n",
      "Min leaf 5 ; Score 0.832718\n",
      "Min leaf 15 ; Score 0.833914\n",
      "Min leaf 30 ; Score 0.833992\n",
      "Min leaf 50 ; Score 0.833900\n",
      "-------------------------------\n",
      "4 -fold\n",
      "Min leaf 5 ; Score 0.843997\n",
      "Min leaf 15 ; Score 0.845583\n",
      "Min leaf 30 ; Score 0.845649\n",
      "Min leaf 50 ; Score 0.845007\n",
      "-------------------------------\n",
      "5 -fold\n",
      "Min leaf 5 ; Score 0.833119\n",
      "Min leaf 15 ; Score 0.833703\n",
      "Min leaf 30 ; Score 0.834331\n",
      "Min leaf 50 ; Score 0.834028\n",
      "-------------------------------\n",
      "5-fold avg nDCG:\n",
      " nDCG_RF-5     0.820204\n",
      "nDCG_RF-15    0.821507\n",
      "nDCG_RF-30    0.821726\n",
      "nDCG_RF-50    0.821539\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "foldnum = 0\n",
    "fold_results = pd.DataFrame()\n",
    "\n",
    "for train, test in kf.split(X_train):\n",
    "    \n",
    "    [tr_data, te_data, tr_labels, te_labels] = folds_to_split(X_train, labels, train, test)\n",
    "    \n",
    "    foldnum+=1\n",
    "    print(foldnum, \"-fold\")\n",
    "\n",
    "    for min_leaf in [5,15,30, 50]:\n",
    "        RF = RandomForestClassifier(n_estimators=600, \n",
    "                                    criterion='gini', \n",
    "                                    min_samples_leaf=min_leaf)\n",
    "\n",
    "        RF.fit(tr_data, tr_labels.values.ravel())\n",
    "        prob_arr_RF = RF.predict_proba(te_data)\n",
    "        score_RF = ndcg_score(te_labels.as_matrix(), prob_arr_RF, k=5)\n",
    "\n",
    "        \n",
    "        fold_results.loc[foldnum, 'nDCG_RF-'+str(min_leaf) ] = score_RF\n",
    "        print(\"Min leaf %d ; Score %f\" %  (min_leaf, score_RF))\n",
    "        \n",
    "    print(\"-------------------------------\")\n",
    "\n",
    "print(\"5-fold avg nDCG:\\n\",fold_results.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### =>min samples leaf = 30 is much better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different max leaf nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -fold\n",
      "Max leaf nodes 5 ; Score 0.766815\n",
      "Max leaf nodes 7 ; Score 0.766815\n",
      "Max leaf nodes 9 ; Score 0.766815\n",
      "Max leaf nodes 11 ; Score 0.770886\n",
      "-------------------------------\n",
      "2 -fold\n",
      "Max leaf nodes 5 ; Score 0.798396\n",
      "Max leaf nodes 7 ; Score 0.798387\n",
      "Max leaf nodes 9 ; Score 0.798360\n",
      "Max leaf nodes 11 ; Score 0.803858\n",
      "-------------------------------\n",
      "3 -fold\n",
      "Max leaf nodes 5 ; Score 0.818011\n",
      "Max leaf nodes 7 ; Score 0.818011\n",
      "Max leaf nodes 9 ; Score 0.818011\n",
      "Max leaf nodes 11 ; Score 0.823768\n",
      "-------------------------------\n",
      "4 -fold\n",
      "Max leaf nodes 5 ; Score 0.828725\n",
      "Max leaf nodes 7 ; Score 0.828725\n",
      "Max leaf nodes 9 ; Score 0.828733\n",
      "Max leaf nodes 11 ; Score 0.830264\n",
      "-------------------------------\n",
      "5 -fold\n",
      "Max leaf nodes 5 ; Score 0.821882\n",
      "Max leaf nodes 7 ; Score 0.821882\n",
      "Max leaf nodes 9 ; Score 0.822340\n",
      "Max leaf nodes 11 ; Score 0.824847\n",
      "-------------------------------\n",
      "5-fold avg nDCG:\n",
      " nDCG_RF-5     0.806766\n",
      "nDCG_RF-7     0.806764\n",
      "nDCG_RF-9     0.806852\n",
      "nDCG_RF-11    0.810725\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "max_depth = 8\n",
    "min_leaf = 30\n",
    "\n",
    "foldnum = 0\n",
    "fold_results = pd.DataFrame()\n",
    "\n",
    "for train, test in kf.split(X_train):\n",
    "    \n",
    "    [tr_data, te_data, tr_labels, te_labels] = folds_to_split(X_train, labels, train, test)\n",
    "    \n",
    "    foldnum+=1\n",
    "    print(foldnum, \"-fold\")\n",
    "\n",
    "    for max_leaf_nodes in range(5,12,2):\n",
    "        RF = RandomForestClassifier(n_estimators=600, \n",
    "                                    criterion='gini', \n",
    "                                    max_depth=max_depth, \n",
    "                                    min_samples_leaf=min_leaf,\n",
    "                                    max_leaf_nodes=max_leaf_nodes)\n",
    "\n",
    "        RF.fit(tr_data, tr_labels.values.ravel())\n",
    "        prob_arr_RF = RF.predict_proba(te_data)\n",
    "        score_RF = ndcg_score(te_labels.as_matrix(), prob_arr_RF, k=5)\n",
    "\n",
    "        \n",
    "        fold_results.loc[foldnum, 'nDCG_RF-'+str(max_leaf_nodes) ] = score_RF\n",
    "        print(\"Max leaf nodes %d ; Score %f\" %  (max_leaf_nodes, score_RF))\n",
    "        \n",
    "    print(\"-------------------------------\")\n",
    "\n",
    "print(\"5-fold avg nDCG:\\n\",fold_results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### =>setting max_lead_nodes decrease the score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameters choosing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -fold\n",
      "Score 0.778541\n",
      "-------------------------------\n",
      "2 -fold\n",
      "Score 0.809750\n",
      "-------------------------------\n",
      "3 -fold\n",
      "Score 0.830342\n",
      "-------------------------------\n",
      "4 -fold\n",
      "Score 0.843567\n",
      "-------------------------------\n",
      "5 -fold\n",
      "Score 0.831990\n",
      "-------------------------------\n",
      "5-fold avg nDCG:\n",
      " nDCG_RF    0.818838\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "foldnum = 0\n",
    "fold_results = pd.DataFrame()\n",
    "\n",
    "for train, test in kf.split(X_train):\n",
    "    \n",
    "    [tr_data, te_data, tr_labels, te_labels] = folds_to_split(X_train, labels, train, test)\n",
    "    \n",
    "    foldnum+=1\n",
    "    print(foldnum, \"-fold\")\n",
    "    \n",
    "    RF = RandomForestClassifier(n_estimators=600, \n",
    "                                criterion='gini', \n",
    "                                max_depth=9, \n",
    "                                min_samples_leaf=30)\n",
    "\n",
    "    RF.fit(tr_data, tr_labels.values.ravel())\n",
    "    prob_arr_RF = RF.predict_proba(te_data)\n",
    "    score_RF = ndcg_score(te_labels.as_matrix(), prob_arr_RF, k=5)\n",
    "\n",
    "\n",
    "    fold_results.loc[foldnum, 'nDCG_RF'] = score_RF\n",
    "    print(\"Score %f\" %  score_RF)\n",
    "        \n",
    "    print(\"-------------------------------\")\n",
    "\n",
    "print(\"5-fold avg nDCG:\\n\",fold_results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -fold\n",
      "Score 0.782007\n",
      "-------------------------------\n",
      "2 -fold\n",
      "Score 0.813039\n",
      "-------------------------------\n",
      "3 -fold\n",
      "Score 0.833896\n",
      "-------------------------------\n",
      "4 -fold\n",
      "Score 0.845821\n",
      "-------------------------------\n",
      "5 -fold\n",
      "Score 0.834231\n",
      "-------------------------------\n",
      "5-fold avg nDCG:\n",
      " nDCG_RF    0.821799\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "foldnum = 0\n",
    "fold_results = pd.DataFrame()\n",
    "\n",
    "for train, test in kf.split(X_train):\n",
    "    \n",
    "    [tr_data, te_data, tr_labels, te_labels] = folds_to_split(X_train, labels, train, test)\n",
    "    \n",
    "    foldnum+=1\n",
    "    print(foldnum, \"-fold\")\n",
    "    \n",
    "    RF = RandomForestClassifier(n_estimators=600, \n",
    "                                criterion='gini', \n",
    "                                min_samples_leaf=30)\n",
    "\n",
    "    RF.fit(tr_data, tr_labels.values.ravel())\n",
    "    prob_arr_RF = RF.predict_proba(te_data)\n",
    "    score_RF = ndcg_score(te_labels.as_matrix(), prob_arr_RF, k=5)\n",
    "\n",
    "\n",
    "    fold_results.loc[foldnum, 'nDCG_RF'] = score_RF\n",
    "    print(\"Score %f\" %  score_RF)\n",
    "        \n",
    "    print(\"-------------------------------\")\n",
    "\n",
    "print(\"5-fold avg nDCG:\\n\",fold_results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the best nDCG score can be reached using decision tree: 0.8217"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -fold\n",
      "Depth:1 - nDCG score:0.780297\n",
      "-------------------------------\n",
      "Depth:2 - nDCG score:0.785215\n",
      "-------------------------------\n",
      "Depth:3 - nDCG score:0.783353\n",
      "-------------------------------\n",
      "Depth:4 - nDCG score:0.780272\n",
      "-------------------------------\n",
      "2 -fold\n",
      "Depth:1 - nDCG score:0.807223\n",
      "-------------------------------\n",
      "Depth:2 - nDCG score:0.812087\n",
      "-------------------------------\n",
      "Depth:3 - nDCG score:0.813787\n",
      "-------------------------------\n",
      "Depth:4 - nDCG score:0.813168\n",
      "-------------------------------\n",
      "3 -fold\n",
      "Depth:1 - nDCG score:0.825931\n",
      "-------------------------------\n",
      "Depth:2 - nDCG score:0.831881\n",
      "-------------------------------\n",
      "Depth:3 - nDCG score:0.834086\n",
      "-------------------------------\n",
      "Depth:4 - nDCG score:0.834455\n",
      "-------------------------------\n",
      "4 -fold\n",
      "Depth:1 - nDCG score:0.839392\n",
      "-------------------------------\n",
      "Depth:2 - nDCG score:0.844959\n",
      "-------------------------------\n",
      "Depth:3 - nDCG score:0.846099\n",
      "-------------------------------\n",
      "Depth:4 - nDCG score:0.843842\n",
      "-------------------------------\n",
      "5 -fold\n",
      "Depth:1 - nDCG score:0.829530\n",
      "-------------------------------\n",
      "Depth:2 - nDCG score:0.834205\n",
      "-------------------------------\n",
      "Depth:3 - nDCG score:0.834181\n",
      "-------------------------------\n",
      "Depth:4 - nDCG score:0.833218\n",
      "-------------------------------\n",
      "5-fold avg nDCG:\n",
      " nDCG_GRB1    0.816475\n",
      "nDCG_GRB2    0.821669\n",
      "nDCG_GRB3    0.822301\n",
      "nDCG_GRB4    0.820991\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "foldnum = 0\n",
    "fold_results = pd.DataFrame()\n",
    "\n",
    "for train, test in kf.split(X_train):\n",
    "    \n",
    "    [tr_data, te_data, tr_labels, te_labels] = folds_to_split(X_train, labels, train, test)\n",
    "    \n",
    "    foldnum+=1\n",
    "    print(foldnum, \"-fold\")\n",
    "\n",
    "    for depth in [1, 2, 3, 4]:\n",
    "        gra_bo_clf = GradientBoostingClassifier(max_depth=depth, \n",
    "                                                n_estimators=100,\n",
    "                                                random_state=1)\n",
    "\n",
    "        gra_bo_clf.fit(tr_data, tr_labels.values.ravel())\n",
    "        prob_arr_gra_bo = gra_bo_clf.predict_proba(te_data)\n",
    "\n",
    "        score_gb = ndcg_score(te_labels.as_matrix(), prob_arr_gra_bo, k=5)\n",
    "        fold_results.loc[foldnum, 'nDCG_GRB' + str(depth)] = score_gb\n",
    "        print(\"Depth:%d - nDCG score:%f\" % (depth, score_gb))\n",
    "        \n",
    "        print(\"-------------------------------\")\n",
    "\n",
    "print(\"5-fold avg nDCG:\\n\",fold_results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different number of estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -fold\n",
      "Number of Estimators:100 - nDCG score:0.783353\n",
      "-------------------------------\n",
      "Number of Estimators:200 - nDCG score:0.782489\n",
      "-------------------------------\n",
      "Number of Estimators:300 - nDCG score:0.781306\n",
      "-------------------------------\n",
      "Number of Estimators:400 - nDCG score:0.780595\n",
      "-------------------------------\n",
      "Number of Estimators:500 - nDCG score:0.780812\n",
      "-------------------------------\n",
      "2 -fold\n",
      "Number of Estimators:100 - nDCG score:0.813787\n",
      "-------------------------------\n",
      "Number of Estimators:200 - nDCG score:0.813489\n",
      "-------------------------------\n",
      "Number of Estimators:300 - nDCG score:0.813047\n",
      "-------------------------------\n",
      "Number of Estimators:400 - nDCG score:0.813119\n",
      "-------------------------------\n",
      "Number of Estimators:500 - nDCG score:0.812628\n",
      "-------------------------------\n",
      "3 -fold\n",
      "Number of Estimators:100 - nDCG score:0.834086\n",
      "-------------------------------\n",
      "Number of Estimators:200 - nDCG score:0.834528\n",
      "-------------------------------\n",
      "Number of Estimators:300 - nDCG score:0.833265\n",
      "-------------------------------\n",
      "Number of Estimators:400 - nDCG score:0.832819\n",
      "-------------------------------\n",
      "Number of Estimators:500 - nDCG score:0.832487\n",
      "-------------------------------\n",
      "4 -fold\n",
      "Number of Estimators:100 - nDCG score:0.846099\n",
      "-------------------------------\n",
      "Number of Estimators:200 - nDCG score:0.845490\n",
      "-------------------------------\n",
      "Number of Estimators:300 - nDCG score:0.844406\n",
      "-------------------------------\n",
      "Number of Estimators:400 - nDCG score:0.843766\n",
      "-------------------------------\n",
      "Number of Estimators:500 - nDCG score:0.843360\n",
      "-------------------------------\n",
      "5 -fold\n",
      "Number of Estimators:100 - nDCG score:0.834181\n",
      "-------------------------------\n",
      "Number of Estimators:200 - nDCG score:0.834166\n",
      "-------------------------------\n",
      "Number of Estimators:300 - nDCG score:0.833748\n",
      "-------------------------------\n",
      "Number of Estimators:400 - nDCG score:0.833358\n",
      "-------------------------------\n",
      "Number of Estimators:500 - nDCG score:0.833044\n",
      "-------------------------------\n",
      "5-fold avg nDCG:\n",
      " nDCG_GRB4    0.820466\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "foldnum = 0\n",
    "fold_results = pd.DataFrame()\n",
    "\n",
    "for train, test in kf.split(X_train):\n",
    "    \n",
    "    [tr_data, te_data, tr_labels, te_labels] = folds_to_split(X_train, labels, train, test)\n",
    "    \n",
    "    foldnum+=1\n",
    "    print(foldnum, \"-fold\")\n",
    "\n",
    "    for num_est in [100, 200, 300, 400, 500]:\n",
    "        gra_bo_clf = GradientBoostingClassifier(n_estimators=num_est, \n",
    "                                                random_state=1)\n",
    "\n",
    "        gra_bo_clf.fit(tr_data, tr_labels.values.ravel())\n",
    "        prob_arr_gra_bo = gra_bo_clf.predict_proba(te_data)\n",
    "\n",
    "        score_gb = ndcg_score(te_labels.as_matrix(), prob_arr_gra_bo, k=5)\n",
    "        fold_results.loc[foldnum, 'nDCG_GRB' + str(num_est)] = score_gb\n",
    "        print(\"Number of Estimators:%d - nDCG score:%f\" % (num_est, score_gb))\n",
    "        \n",
    "        print(\"-------------------------------\")\n",
    "\n",
    "print(\"5-fold avg nDCG:\\n\",fold_results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters choosing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -fold\n",
      "nDCG score:0.783353\n",
      "-------------------------------\n",
      "2 -fold\n",
      "nDCG score:0.813787\n",
      "-------------------------------\n",
      "3 -fold\n",
      "nDCG score:0.834086\n",
      "-------------------------------\n",
      "4 -fold\n",
      "nDCG score:0.846099\n",
      "-------------------------------\n",
      "5 -fold\n",
      "nDCG score:0.834181\n",
      "-------------------------------\n",
      "5-fold avg nDCG:\n",
      " nDCG_GRB    0.822301\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "foldnum = 0\n",
    "fold_results = pd.DataFrame()\n",
    "\n",
    "for train, test in kf.split(X_train):\n",
    "    \n",
    "    [tr_data, te_data, tr_labels, te_labels] = folds_to_split(X_train, labels, train, test)\n",
    "    \n",
    "    foldnum+=1\n",
    "    print(foldnum, \"-fold\")\n",
    "\n",
    "\n",
    "    gra_bo_clf = GradientBoostingClassifier(max_depth=3, \n",
    "                                            n_estimators=100,\n",
    "                                            random_state=1)\n",
    "\n",
    "    gra_bo_clf.fit(tr_data, tr_labels.values.ravel())\n",
    "    prob_arr_gra_bo = gra_bo_clf.predict_proba(te_data)\n",
    "\n",
    "    score_gb = ndcg_score(te_labels.as_matrix(), prob_arr_gra_bo, k=5)\n",
    "    fold_results.loc[foldnum, 'nDCG_GRB'] = score_gb\n",
    "    print(\"nDCG score:%f\" % (score_gb))\n",
    "\n",
    "    print(\"-------------------------------\")\n",
    "\n",
    "print(\"5-fold avg nDCG:\\n\",fold_results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the best nDCG score can be reached using gradient boosting: 0.8223"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
